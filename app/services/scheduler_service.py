import time
import humanize
from datetime import datetime, timedelta
from typing import Dict, List, Optional

from app.models.stats import UploadStats  
from app.models.schedule import Schedule
from app.models.sync_history import SyncHistory
from app.utils.config import validate_environment, upload_stats, get_config, get_file_categories
from app.services.file_scanner import scan_backup_files
from app.services.s3_client import test_connection, get_existing_s3_files
from app.services.upload_manager import upload_files
from app.services.job_scheduler import JobScheduler
from app.utils.debug_logger import DebugLogger
from app.utils.schedule_storage import ScheduleStorage
from app.utils.sync_history_db import (
    create_sync_history, update_sync_history, get_sync_history as get_sync_history_db,
    convert_db_to_dataclass
)

class SchedulerService:
    """–û—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è–º–∏"""
    
    def __init__(self, schedule_file: str = 'data/schedules.json'):
        self.job_scheduler = JobScheduler()
        self.storage = ScheduleStorage(schedule_file)
        self.debug_logger = DebugLogger()
        
        self.schedules: Dict[str, Schedule] = {}
        self.max_history_entries = 100
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ socketio –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
        self.socketio = None
        self._stop_stats_monitor = False
        
        self.load_schedules()
    
    def set_socketio(self, socketio):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç socketio –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π"""
        self.socketio = socketio
    
    def load_schedules(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π (–∏—Å—Ç–æ—Ä–∏—è —Ç–µ–ø–µ—Ä—å –≤ –ë–î)"""
        self.schedules, _ = self.storage.load_schedules()  # –ò—Å—Ç–æ—Ä–∏—è –±–æ–ª—å—à–µ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ JSON
        self.debug_logger.info(f"Loaded {len(self.schedules)} schedules (history is in DB)")
    
    def save_schedules(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π (–∏—Å—Ç–æ—Ä–∏—è —Ç–µ–ø–µ—Ä—å –≤ –ë–î)"""
        self.storage.save_schedules(self.schedules, [], self.max_history_entries)  # –ò—Å—Ç–æ—Ä–∏—è –±–æ–ª—å—à–µ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ JSON
    
    def add_schedule(
        self,
        schedule_id: str,
        name: str,
        schedule_type: str,
        interval: str,
        enabled: bool = True,
        categories: Optional[List[str]] = None,
        file_extensions: Optional[List[str]] = None,
        config_id: Optional[int] = None,
        user_id: Optional[int] = None,
        source_directory: Optional[str] = None
    ) -> bool:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è"""
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
            if schedule_type == 'interval':
                try:
                    interval_minutes = int(interval)
                    if interval_minutes <= 0:
                        raise ValueError("Interval must be positive")
                except (ValueError, TypeError):
                    self.debug_logger.error(f"Invalid interval value: {interval}")
                    return False

            schedule = Schedule(
                id=schedule_id,
                name=name,
                schedule_type=schedule_type,
                interval=interval,
                enabled=enabled,
                categories=categories or None,
                file_extensions=file_extensions or None,
                config_id=config_id,
                user_id=user_id,
                source_directory=source_directory
            )
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
            schedule.validate()
            
            self.schedules[schedule_id] = schedule
            
            if enabled:
                self.job_scheduler.schedule_job(schedule, self.run_scheduled_sync, (schedule,))
            
            self.save_schedules()
            self.debug_logger.info(f"Added schedule: {name} ({schedule_type}: {interval})")
            return True
            
        except Exception as e:
            self.debug_logger.error(f"Error adding schedule: {e}")
            return False

    def update_schedule(self, schedule_id: str, **kwargs) -> bool:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è"""
        if schedule_id not in self.schedules:
            return False
            
        try:
            old_enabled = self.schedules[schedule_id].enabled
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã
            for key, value in kwargs.items():
                if hasattr(self.schedules[schedule_id], key):
                    setattr(self.schedules[schedule_id], key, value)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
            self.schedules[schedule_id].validate()
            
            new_enabled = self.schedules[schedule_id].enabled
            
            # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞–Ω–∏–µ –µ—Å–ª–∏ –æ–Ω–æ –≤–∫–ª—é—á–µ–Ω–æ
            if new_enabled:
                self.job_scheduler.unschedule_job(schedule_id)
                self.job_scheduler.schedule_job(self.schedules[schedule_id], self.run_scheduled_sync, (self.schedules[schedule_id],))
            else:
                self.job_scheduler.unschedule_job(schedule_id)
                
            self.save_schedules()
            self.debug_logger.info(f"Updated schedule: {schedule_id}")
            return True
            
        except Exception as e:
            self.debug_logger.error(f"Error updating schedule: {e}")
            return False

    def delete_schedule(self, schedule_id: str) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è"""
        if schedule_id in self.schedules:
            schedule_name = self.schedules[schedule_id].name
            self.job_scheduler.unschedule_job(schedule_id)
            del self.schedules[schedule_id]
            self.save_schedules()
            self.debug_logger.info(f"Deleted schedule: {schedule_name}")
            return True
        return False

    def run_scheduled_sync(self, schedule: Schedule):
        """–ó–∞–ø—É—Å–∫ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"""
        self.debug_logger.info(f"=== üöÄ STARTING SCHEDULED SYNC: {schedule.name} ({schedule.id}) ===")
        self.debug_logger.info(f"üìÖ Schedule details: type={schedule.schedule_type.value}, interval={schedule.interval}, enabled={schedule.enabled}")
        
        # –ü–æ–ª—É—á–∞–µ–º user_id –∏ config_id –∏–∑ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
        user_id = schedule.user_id
        config_id = schedule.config_id
        
        if not user_id:
            self.debug_logger.error(f"‚ùå Schedule {schedule.id} has no user_id! Cannot run sync.")
            return
        
        self.debug_logger.info(f"üë§ Using user_id={user_id}, config_id={config_id}")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ –∏—Å—Ç–æ—Ä–∏–∏ –≤ –ë–î
        history_id = None
        original_stats = None
        
        try:
            history_id = create_sync_history(
                schedule_id=schedule.id,
                schedule_name=schedule.name,
                user_id=user_id,
                status='running'
            )
            self.debug_logger.info(f"‚úÖ History entry created in DB with id={history_id}")
        
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –î–û try –±–ª–æ–∫–∞
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            original_stats = UploadStats(
                total_files=upload_stats.total_files,
                successful=upload_stats.successful,
                failed=upload_stats.failed,
                total_bytes=upload_stats.total_bytes,
                uploaded_bytes=upload_stats.uploaded_bytes,
                start_time=upload_stats.start_time,
                file_start_times=upload_stats.file_start_times.copy() if upload_stats.file_start_times else {},
                is_running=upload_stats.is_running,
                skipped_existing=upload_stats.skipped_existing,
                skipped_time=upload_stats.skipped_time
            )
            
            # –®–∞–≥ 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self._init_upload_stats(user_id=user_id)
            self.debug_logger.info(" Upload stats initialized")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self._send_stats_update()
            
            # –®–∞–≥ 2: –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            self.debug_logger.info("üîß Validating environment...")
            self._validate_environment(user_id=user_id)
            self.debug_logger.info(" Environment validation passed")
            
            # –®–∞–≥ 3: –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ S3
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º config_id –∏–∑ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            current_config = get_config(user_id=user_id, config_id=config_id)
            if config_id:
                self.debug_logger.info(f"‚úÖ Using specific config_id={config_id} for user_id={user_id}")
            else:
                self.debug_logger.info(f"‚úÖ Using default config for user_id={user_id}")
            
            selected_categories = schedule.categories or get_file_categories(user_id=user_id, config_id=config_id)
            file_extensions = schedule.file_extensions
            
            if file_extensions:
                self.debug_logger.info(f" Applying file extensions filter: {', '.join(file_extensions)}")
            elif selected_categories:
                self.debug_logger.info(f" Applying categories filter: {', '.join(selected_categories)}")

            self.debug_logger.info(" Getting existing S3 files...")
            existing_files = get_existing_s3_files(user_id=user_id)
            self.debug_logger.info(f" Found {len(existing_files)} existing files in S3")
            
            # –®–∞–≥ 4: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –±—ç–∫–∞–ø–∞
            source_directory = schedule.source_directory  # –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏–∑ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
            if source_directory:
                self.debug_logger.info(f"üìÅ Using source directory: {source_directory}")
            
            self.debug_logger.info(" Scanning backup files...")
            files_to_upload = scan_backup_files(
                existing_s3_files=existing_files,
                categories=selected_categories if not file_extensions else None,
                file_extensions=file_extensions,
                user_id=user_id,
                config_id=config_id,
                source_directory=source_directory
            )
            self.debug_logger.info(f" Scan completed: {len(files_to_upload)} files to upload")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Å–ª–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            self._send_stats_update()
            
            if files_to_upload:
                total_size = sum(f[3] for f in files_to_upload)
                self.debug_logger.info(f" Starting upload of {len(files_to_upload)} files, total size: {humanize.naturalsize(total_size)}")
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
                stats_monitor_thread = self._start_stats_monitor()
                
                # –®–∞–≥ 5: –ó–ê–ü–£–°–ö –ó–ê–ì–†–£–ó–ö–ò —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                storage_class = current_config.get('STORAGE_CLASS', 'STANDARD')
                self.debug_logger.info(f" CALLING upload_files() with storage_class={storage_class}...")
                successful, failed = upload_files(
                    files_to_upload, 
                    user_id=user_id, 
                    storage_class=storage_class,
                    config_id=config_id
                )
                self.debug_logger.info(f" upload_files() returned: {successful} successful, {failed} failed")
                
                # –ñ–î–ï–ú –ó–ê–í–ï–†–®–ï–ù–ò–Ø –í–°–ï–• –ü–û–¢–û–ö–û–í –ó–ê–ì–†–£–ó–ö–ò
                self.debug_logger.info(" Waiting for all upload threads to complete...")
                max_wait_time = 3600  # 1 —á–∞—Å –º–∞–∫—Å–∏–º—É–º
                wait_interval = 5     # –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
                waited = 0
                
                while upload_stats.is_running and waited < max_wait_time:
                    time.sleep(wait_interval)
                    waited += wait_interval
                    if waited % 30 == 0:  # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
                        self.debug_logger.info(f"‚è± Waiting for upload to complete... {waited}s elapsed")
                
                if upload_stats.is_running:
                    self.debug_logger.warning(" Upload timeout reached, forcing stop")
                    upload_stats.is_running = False
                
                # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                self._stop_stats_monitor = True
                if stats_monitor_thread and stats_monitor_thread.is_alive():
                    stats_monitor_thread.join(timeout=5)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –≤ –ë–î —Å –∞–∫—Ç—É–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
                duration = time.time() - upload_stats.start_time
                if history_id:
                    update_sync_history(
                        history_id=history_id,
                        status='completed',
                        files_uploaded=upload_stats.successful,
                        files_failed=upload_stats.failed,
                        total_size=upload_stats.total_bytes,
                        uploaded_size=upload_stats.uploaded_bytes,
                        duration=duration
                    )
                
                self.debug_logger.info(f" Scheduled sync completed: {upload_stats.successful} successful, {upload_stats.failed} failed, duration: {duration:.2f}s")
                
            else:
                if history_id:
                    duration = time.time() - upload_stats.start_time
                    update_sync_history(
                        history_id=history_id,
                        status='completed',
                        files_uploaded=0,
                        files_failed=0,
                        total_size=0,
                        uploaded_size=0,
                        duration=duration
                    )
                self.debug_logger.info(" Scheduled sync: No files to upload")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
            schedule.last_run = datetime.now().isoformat()
            next_run = self.job_scheduler.get_next_run_time(schedule.id)
            schedule.next_run = next_run.isoformat() if next_run else None
            self.save_schedules()
            self.debug_logger.info(" Schedule updated with last_run and next_run")
            
        except Exception as e:
            self.debug_logger.error(f" Scheduled sync error: {e}")
            import traceback
            self.debug_logger.error(f" Stack trace: {traceback.format_exc()}")
            
            if history_id:
                duration = time.time() - (upload_stats.start_time if hasattr(upload_stats, 'start_time') and upload_stats.start_time > 0 else time.time())
                update_sync_history(
                    history_id=history_id,
                    status='failed',
                    error=str(e),
                    duration=duration
                )
            self.save_schedules()
            
        finally:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–æ –±—ã–ª–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ
            if original_stats:
                self.debug_logger.info(" Restoring original upload stats...")
                upload_stats.total_files = original_stats.total_files
                upload_stats.successful = original_stats.successful
                upload_stats.failed = original_stats.failed
                upload_stats.total_bytes = original_stats.total_bytes
                upload_stats.uploaded_bytes = original_stats.uploaded_bytes
                upload_stats.start_time = original_stats.start_time
                upload_stats.file_start_times = original_stats.file_start_times
                upload_stats.is_running = original_stats.is_running
                upload_stats.skipped_existing = original_stats.skipped_existing
                upload_stats.skipped_time = original_stats.skipped_time
                self.debug_logger.info(" Original upload stats restored")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self._send_stats_update()
            
            self.debug_logger.info(f"===  SCHEDULED SYNC FINISHED: {schedule.name} ===\n")

    def _init_upload_stats(self, user_id: Optional[int] = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏"""
        upload_stats.total_files = 0
        upload_stats.successful = 0
        upload_stats.failed = 0
        upload_stats.total_bytes = 0
        upload_stats.uploaded_bytes = 0
        upload_stats.start_time = time.time()
        upload_stats.file_start_times = {}
        upload_stats.is_running = True
        upload_stats.skipped_existing = 0
        upload_stats.skipped_time = 0
        if user_id:
            upload_stats.user_id = user_id

    def _validate_environment(self, user_id: Optional[int] = None):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        validate_environment(user_id=user_id)
        
        if not test_connection(user_id=user_id):
            raise Exception(f"S3 connection test failed for user_id={user_id}")

    def _start_stats_monitor(self):
        """–ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏"""
        self._stop_stats_monitor = False
        
        def stats_monitor():
            while not self._stop_stats_monitor and upload_stats.is_running:
                try:
                    self._send_stats_update()
                    time.sleep(2)  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã
                except Exception as e:
                    self.debug_logger.error(f"Error in stats monitor: {e}")
                    time.sleep(5)
        
        import threading
        thread = threading.Thread(target=stats_monitor, daemon=True)
        thread.start()
        return thread

    def _send_stats_update(self):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —á–µ—Ä–µ–∑ Socket.IO"""
        try:
            if self.socketio:
                from app.web.background_tasks import get_stats_data
                stats_data = get_stats_data()
                self.socketio.emit('stats_update', stats_data)
                self.debug_logger.debug(" Stats update sent to web interface")
        except Exception as e:
            self.debug_logger.error(f"Error sending stats update: {e}")

    def get_sync_history(self, limit: int = 50, schedule_id: Optional[str] = None, period: str = 'all', user_id: Optional[int] = None) -> List[SyncHistory]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–π —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –∏–∑ –ë–î"""
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏–∑ –ë–î
        db_history = get_sync_history_db(
            schedule_id=schedule_id if schedule_id and schedule_id != 'all' else None,
            user_id=user_id,
            limit=limit,
            period=period
        )
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ dataclass –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        return [convert_db_to_dataclass(entry) for entry in db_history]

    def get_schedule_stats(self, schedule_id: str) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –∏–∑ –ë–î"""
        schedule_history_db = get_sync_history_db(schedule_id=schedule_id, limit=1000)
        
        if not schedule_history_db:
            return {}
        
        schedule_history = [convert_db_to_dataclass(h) for h in schedule_history_db]
            
        successful_runs = [h for h in schedule_history if h.status.value == 'completed']
        failed_runs = [h for h in schedule_history if h.status.value == 'failed']
        
        total_files = sum(h.files_uploaded for h in successful_runs if hasattr(h, 'files_uploaded'))
        total_data = sum(h.uploaded_size for h in successful_runs if hasattr(h, 'uploaded_size'))
        total_duration = sum(h.duration for h in successful_runs if hasattr(h, 'duration'))
        
        avg_duration = total_duration / len(successful_runs) if successful_runs else 0
        
        last_run = schedule_history[-1] if schedule_history else None
        
        return {
            'total_runs': len(schedule_history),
            'successful_runs': len(successful_runs),
            'failed_runs': len(failed_runs),
            'success_rate': (len(successful_runs) / len(schedule_history) * 100) if schedule_history else 0,
            'total_files_uploaded': total_files,
            'total_data_uploaded': humanize.naturalsize(total_data) if total_data > 0 else "0 B",
            'total_data_uploaded_bytes': total_data,
            'average_duration': avg_duration,
            'last_run': last_run.to_dict() if last_run else None
        }

    def get_all_schedules_stats(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –≤—Å–µ—Ö —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π –∏–∑ –ë–î"""
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é –∏–∑ –ë–î
        all_history_db = get_sync_history_db(limit=10000)
        all_history = [convert_db_to_dataclass(h) for h in all_history_db]
        
        stats = {
            'total_schedules': len(self.schedules),
            'enabled_schedules': len([s for s in self.schedules.values() if s.enabled]),
            'total_runs': len(all_history),
            'successful_runs': len([h for h in all_history if h.status.value == 'completed']),
            'failed_runs': len([h for h in all_history if h.status.value == 'failed']),
            'total_files_uploaded': sum(h.files_uploaded for h in all_history if hasattr(h, 'files_uploaded')),
            'total_data_uploaded_bytes': sum(h.uploaded_size for h in all_history if hasattr(h, 'uploaded_size')),
        }
        
        # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤
        if stats['total_runs'] > 0:
            stats['success_rate'] = (stats['successful_runs'] / stats['total_runs']) * 100
        else:
            stats['success_rate'] = 0
            
        stats['total_data_uploaded'] = humanize.naturalsize(stats['total_data_uploaded_bytes'])
        
        return stats

    def start(self):
        """–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
        self.job_scheduler.start()
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –≤–∫–ª—é—á–µ–Ω–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è
        enabled_count = 0
        for schedule in self.schedules.values():
            if schedule.enabled:
                try:
                    self.job_scheduler.schedule_job(schedule, self.run_scheduled_sync, (schedule,))
                    enabled_count += 1
                    self.debug_logger.info(f" Restored schedule: {schedule.name}")
                except Exception as e:
                    self.debug_logger.error(f" Failed to restore schedule {schedule.name}: {e}")
        
        self.debug_logger.info(f"üöÄ Scheduler started, restored {enabled_count} enabled schedules")

    def shutdown(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
        try:
            if hasattr(self.job_scheduler, 'scheduler') and self.job_scheduler.scheduler.running:
                self.job_scheduler.shutdown()
                self.debug_logger.info(" Scheduler service stopped")
            else:
                self.debug_logger.debug("‚Ñπ Scheduler was not running, skip shutdown")
        except Exception as e:
            self.debug_logger.error(f" Error stopping scheduler service: {e}")

    def get_storage_info(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
        return self.storage.get_storage_info()

    # –ú–µ—Ç–æ–¥—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ—Ç–ª–∞–¥–æ—á–Ω—ã–º–∏ –ª–æ–≥–∞–º–∏
    def get_debug_logs(self, level: str = 'INFO', limit: int = 100):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö –ª–æ–≥–æ–≤"""
        return self.debug_logger.get_logs(level, limit)
    
    def clear_debug_logs(self) -> bool:
        """–û—á–∏—Å—Ç–∫–∞ –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö –ª–æ–≥–æ–≤"""
        return self.debug_logger.clear_logs()
    
    def info(self, message: str):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        self.debug_logger.info(message)
    
    def error(self, message: str):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏"""
        self.debug_logger.error(message)
    
    def debug(self, message: str):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        self.debug_logger.debug(message)

    def run_schedule_immediately(self, schedule_id: str) -> bool:
        """–ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è"""
        if schedule_id not in self.schedules:
            return False
            
        try:
            schedule = self.schedules[schedule_id]
            self.debug_logger.info(f" Manually running schedule: {schedule.name}")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            import threading
            thread = threading.Thread(target=self.run_scheduled_sync, args=(schedule,), daemon=True)
            thread.start()
            
            return True
        except Exception as e:
            self.debug_logger.error(f" Error running schedule immediately: {e}")
            return False

    def get_schedule_by_id(self, schedule_id: str) -> Optional[Schedule]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –ø–æ ID"""
        return self.schedules.get(schedule_id)

    def get_next_run_time(self, schedule_id: str) -> Optional[datetime]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞"""
        return self.job_scheduler.get_next_run_time(schedule_id)

    def is_schedule_enabled(self, schedule_id: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∫–ª—é—á–µ–Ω–æ –ª–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ"""
        schedule = self.schedules.get(schedule_id)
        return schedule.enabled if schedule else False

    def enable_schedule(self, schedule_id: str) -> bool:
        """–í–∫–ª—é—á–µ–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è"""
        return self.update_schedule(schedule_id, enabled=True)

    def disable_schedule(self, schedule_id: str) -> bool:
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è"""
        return self.update_schedule(schedule_id, enabled=False)

    def validate_schedule_config(self, schedule_type: str, interval: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è"""
        try:
            if schedule_type == 'interval':
                interval_minutes = int(interval)
                if interval_minutes <= 0:
                    return False
            elif schedule_type == 'cron':
                # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è cron –≤—ã—Ä–∞–∂–µ–Ω–∏—è
                if not interval or len(interval.split()) != 5:
                    return False
            else:
                return False
            return True
        except (ValueError, TypeError):
            return False

    def get_schedule_display_info(self, schedule_id: str) -> Optional[dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        schedule = self.schedules.get(schedule_id)
        if not schedule:
            return None
            
        stats = self.get_schedule_stats(schedule_id)
        
        return {
            'id': schedule.id,
            'name': schedule.name,
            'type': schedule.schedule_type.value,
            'interval': schedule.interval,
            'enabled': schedule.enabled,
            'created_at': schedule.created_at,
            'last_run': schedule.last_run,
            'next_run': schedule.next_run,
            'description': schedule.description,
            'interval_display': schedule.get_interval_display(),
            'stats': stats
        }

    def cleanup_old_history(self, max_age_days: int = 30) -> int:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑ –ë–î"""
        from datetime import timedelta
        from app.db import session_scope
        from app.models.db_models import SyncHistoryDB
        
        cutoff_date = datetime.utcnow() - timedelta(days=max_age_days)
        
        with session_scope() as session:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –¥–æ —É–¥–∞–ª–µ–Ω–∏—è
            initial_count = session.query(SyncHistoryDB).filter(
                SyncHistoryDB.start_time < cutoff_date
            ).count()
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
            deleted_count = session.query(SyncHistoryDB).filter(
                SyncHistoryDB.start_time < cutoff_date
            ).delete()
            
            # session_scope —Å–∞–º –¥–µ–ª–∞–µ—Ç commit, –ø–æ—ç—Ç–æ–º—É —É–¥–∞–ª—è–µ–º session.commit()
            
            if deleted_count > 0:
                self.debug_logger.info(f" Cleaned up {deleted_count} old history entries from DB")
            
            return deleted_count

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
scheduler_service = SchedulerService()